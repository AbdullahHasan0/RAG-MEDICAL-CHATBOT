 ğŸš€ RAG Chatbot with End-to-End CI/CD Deployment

An end-to-end **Retrieval-Augmented Generation (RAG) chatbot** project, fully containerized with **Docker**, automated via **Jenkins CI/CD pipeline**, scanned for vulnerabilities with **Trivy**, and deployed on **AWS App Runner** using **ECR**.

---

## ğŸ“Œ Features
- ğŸ§  **RAG Pipeline** â€“ Ingests domain-specific documents, chunks text, and retrieves context for LLM-powered answers.  
- ğŸ³ **Containerization** â€“ Built Docker images for reproducible environments.  
- âš¡ **CI/CD Pipeline** â€“ Automated with Jenkins:
  - Code checkout from GitHub  
  - Docker build & Trivy security scan  
  - Push to AWS Elastic Container Registry (ECR)  
  - Deploy to AWS App Runner  
- ğŸ” **Security** â€“ Integrated Trivy for container vulnerability scanning.  
- â˜ï¸ **Cloud Deployment** â€“ Scalable chatbot hosted on AWS App Runner.  

---

## ğŸ—ï¸ Tech Stack
- **Backend**: Python, FastAPI/Flask (depending on your code)  
- **LLM**: HuggingFace Transformers / SentenceTransformers  
- **CI/CD**: Jenkins (Docker-in-Docker setup)  
- **Security**: Trivy  
- **Cloud**: AWS ECR + App Runner  
- **Containerization**: Docker  

---

## ğŸ”‘ Environment Variables

This project requires the **OpenAI API key** for LLM access.

1. Create a `.env` file in the root directory:
```env
OPENAI_API_KEY=your_openai_api_key_here
```

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/AbdullahHasan0/RAG-MEDICAL-CHATBOT
```

## 2ï¸âƒ£ Create Virtual Environment (Local Development)
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
pip install -e .
```

## 3ï¸âƒ£ Run Locally
```bash
python .\app\application.py
```

Visit: ```http://localhost:8000```
